{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ac0fb26",
   "metadata": {},
   "source": [
    "# Sentiment Classification with BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3006ee",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bcdf22ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, average_precision_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d20b99e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da146b29",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c78ba10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset('imdb', split = 'test')\n",
    "\n",
    "y = np.array(data['label'])\n",
    "X = np.array(data['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa47ff78",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "00d7b2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 25000\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:', len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23b9c761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of text: 228.52668\n",
      "Min length of text: 4\n",
      "Max length of text: 2278\n",
      "Median length of text: 172.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "len_of_text = [len(text.split()) for text in X]\n",
    "\n",
    "print('Average length of text:', np.mean(len_of_text))\n",
    "print('Min length of text:', np.min(len_of_text))\n",
    "print('Max length of text:', np.max(len_of_text))\n",
    "print('Median length of text:', np.median(len_of_text))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc2fd39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of positive reviews in set: 50.0\n"
     ]
    }
   ],
   "source": [
    "print('Percent of positive reviews in set:', np.mean(y) * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a73b06",
   "metadata": {},
   "source": [
    "## Example Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3679847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example positive review:\n",
      "Fun, entertaining movie about WWII German spy (Julie Andrews!) falling in love with American pilot (Rock Hudson), while trying to get secrets from him. For some reason this was attacked by critics and shunned by the public in 1970--I can't see why. It's beautifully shot, has wonderful costumes and interiors, and exciting aerial dogfights. Also it has Andrews doing a strip-tease (strictly PG material) and singing a beautiful song--\"Whistling in the Dark\". The movie does have problems. Andrews and Hudson did not get along during the shooting of this--and it shows. Their love scenes lack spark and they have zero sexual chemistry. Still, they turn in OK performances. The film is a little long (even in the 105 min director's cut I saw) and gets way too dark and serious at the end. Still, worth catching. Try seeing the directors cut...the other one runs half an hour longer!\n",
      "\n",
      "Example negative review:\n",
      "I of course saw the previews for this at the beginning of some other Lion's Gate extravaganza, so of course it was only the best parts and therefore looked intriguing. And it is, to a point. A young college student (Sarah)is finding riddles all over the place and is becoming obsessed with answering them, and in doing so she's unwittingly becoming involved in some game. Now that's fairly intriguing right there but unfortunately it all gets rather muddled and becomes so complicated that the viewer (like myself) will most likely become frustrated. Characters appear with little introduction and you're not really sure who they are or why Sarah knows them or is hanging out with them. All of this has something to do with this woman who tried to drown a young boy years ago and her reason for that was that it's \"all part of the design\". In reality, it's all part of the \"very sketchy script\" and when the film is over you'll find yourself feeling that you've lost about an hour and a half of your life that you want back for more productive uses of your time, like cleaning the bathroom, for instance. 4 out of 10.\n"
     ]
    }
   ],
   "source": [
    "print('Example positive review:')\n",
    "print(X[y == 1][65])\n",
    "print()\n",
    "\n",
    "print('Example negative review:')\n",
    "print(X[y == 0][25])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddb5d20",
   "metadata": {},
   "source": [
    "## Simple Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64286497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproccess_text(text): \n",
    "    return text.strip().lower()\n",
    "\n",
    "X = [preproccess_text(text) for text in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c59ef6",
   "metadata": {},
   "source": [
    "## Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "195413b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bdacc2",
   "metadata": {},
   "source": [
    "## Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6d1b20bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text): \n",
    "    inputs = tokenizer(text, return_tensors = 'pt', truncation = True, padding = True).to(device) \n",
    "    outputs = model(**inputs) \n",
    "    probs = F.softmax(outputs.logits, dim = 1) \n",
    "    label = torch.argmax(probs, dim = 1)\n",
    "    return label, probs[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab15b491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0]),\n",
       " tensor([3.8375e-04, 3.8294e-01, 2.8993e-04, 4.2437e-03],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(X[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e36119",
   "metadata": {},
   "source": [
    "## Predict on Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "47c58e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 64 samples...\n",
      "Processed 704 samples...\n",
      "Processed 1344 samples...\n",
      "Processed 1984 samples...\n",
      "Processed 2624 samples...\n",
      "Processed 3264 samples...\n",
      "Processed 3904 samples...\n",
      "Processed 4544 samples...\n",
      "Processed 5184 samples...\n",
      "Processed 5824 samples...\n",
      "Processed 6464 samples...\n",
      "Processed 7104 samples...\n",
      "Processed 7744 samples...\n",
      "Processed 8384 samples...\n",
      "Processed 9024 samples...\n",
      "Processed 9664 samples...\n",
      "Processed 10304 samples...\n",
      "Processed 10944 samples...\n",
      "Processed 11584 samples...\n",
      "Processed 12224 samples...\n",
      "Processed 12864 samples...\n",
      "Processed 13504 samples...\n",
      "Processed 14144 samples...\n",
      "Processed 14784 samples...\n",
      "Processed 15424 samples...\n",
      "Processed 16064 samples...\n",
      "Processed 16704 samples...\n",
      "Processed 17344 samples...\n",
      "Processed 17984 samples...\n",
      "Processed 18624 samples...\n",
      "Processed 19264 samples...\n",
      "Processed 19904 samples...\n",
      "Processed 20544 samples...\n",
      "Processed 21184 samples...\n",
      "Processed 21824 samples...\n",
      "Processed 22464 samples...\n",
      "Processed 23104 samples...\n",
      "Processed 23744 samples...\n",
      "Processed 24384 samples...\n",
      "Processed 25000 samples...\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred, pred_proba = [], []\n",
    "    for i in range(0, len(X), BATCH_SIZE):\n",
    "        batch = X[i:i + BATCH_SIZE]\n",
    "        labels, probs = predict_sentiment(batch)\n",
    "        pred.extend(labels.cpu().numpy())\n",
    "        pred_proba.extend(probs.detach().cpu().numpy())\n",
    "\n",
    "        if i % 640 == 0: \n",
    "            print(f'Processed {i + len(batch)} samples...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9f50be9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89072\n",
      "F1 score: 0.8874794069192751\n",
      "Precision: 0.9146010186757215\n",
      "Recall: 0.86192\n",
      "ROC AUC: 0.9587060063999999\n",
      "Average Precision: 0.9576490987225383\n",
      "Confusion matrix:\n",
      "[[11494  1006]\n",
      " [ 1726 10774]]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy_score(y, pred))\n",
    "print('F1 score:', f1_score(y, pred))\n",
    "print('Precision:', precision_score(y, pred))\n",
    "print('Recall:', recall_score(y, pred))\n",
    "print('ROC AUC:', roc_auc_score(y, pred_proba))\n",
    "print('Average Precision:', average_precision_score(y, pred_proba))\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338903b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docker-testing-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
